{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import glob\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn import preprocessing\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import accuracy_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import layers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Activation, Dense, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid','softmax']),\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid','softmax']),\n",
      "        'Dense_1': hp.choice('Dense_1', [256, 512, 1024]),\n",
      "        'Activation_2': hp.choice('Activation_2', ['relu', 'sigmoid','softmax']),\n",
      "        'Activation_3': hp.choice('Activation_3', ['three', 'four']),\n",
      "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
      "        'Dense_2': hp.choice('Dense_2', [256, 512, 1024]),\n",
      "        'Activation_4': hp.choice('Activation_4', ['relu', 'sigmoid','softmax']),\n",
      "        'Activation_5': hp.choice('Activation_5', ['relu', 'sigmoid','softmax']),\n",
      "        'optimizer': hp.choice('optimizer', ['rmsprop', 'adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [16, 32]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "   1: \n",
      "   2: \"\"\"\n",
      "   3: Data providing function:\n",
      "   4: \n",
      "   5: This function is separated from create_model() so that hyperopt\n",
      "   6: won't reload data for each evaluation run.\n",
      "   7: \"\"\"\n",
      "   8: df = pd.read_csv(\"./stockPrice.csv\", header=0, na_values='.')\n",
      "   9: \n",
      "  10: lol = df.copy()\n",
      "  11: lol[\"1pred\"] = (df[\"close\"].shift(-1) - df[\"close\"]) / df[\"close\"]\n",
      "  12: lol[\"3pred\"] = (df[\"close\"].shift(-3) - df[\"close\"]) / df[\"close\"]\n",
      "  13: lol[\"5pred\"] = (df[\"close\"].shift(-5) - df[\"close\"]) / df[\"close\"]\n",
      "  14: lol[\"10pred\"] = (df[\"close\"].shift(-10) - df[\"close\"]) / df[\"close\"]\n",
      "  15: \n",
      "  16: lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '1predB'] = 0\n",
      "  17: lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '1predB'] = 1\n",
      "  18: lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '3predB'] = 0\n",
      "  19: lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '3predB'] = 1\n",
      "  20: lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '5predB'] = 0\n",
      "  21: lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '5predB'] = 1\n",
      "  22: lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '10predB'] = 0\n",
      "  23: lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '10predB'] = 1\n",
      "  24: \n",
      "  25: lol[\"5max\"] = lol[\"close\"].rolling(window=5).max()\n",
      "  26: lol[\"10max\"] = lol[\"close\"].rolling(window=10).max()\n",
      "  27: lol[\"20max\"] = lol[\"close\"].rolling(window=20).max()\n",
      "  28: \n",
      "  29: lol[\"5low\"] = lol[\"close\"].rolling(window=5).min()\n",
      "  30: lol[\"10low\"] = lol[\"close\"].rolling(window=10).min()\n",
      "  31: lol[\"20low\"] = lol[\"close\"].rolling(window=20).min()\n",
      "  32: \n",
      "  33: lol[\"vol%\"] =  (df[\"vol\"] - df[\"vol\"].shift(1)) /df[\"vol\"].shift(1)\n",
      "  34: \n",
      "  35: lol = lol.dropna()    \n",
      "  36: \n",
      "  37: dfC = pd.DataFrame()\n",
      "  38: dfC[\"vol\"] = lol[\"vol%\"]\n",
      "  39: dfC[\"sma10\"] = lol[\"sma10\"] / lol[\"close\"]\n",
      "  40: dfC[\"sma20\"] = lol[\"sma20\"] / lol[\"close\"]\n",
      "  41: dfC[\"sma50\"] = lol[\"sma50\"] / lol[\"close\"]\n",
      "  42: dfC[\"sma100\"] = lol[\"sma100\"] / lol[\"close\"]\n",
      "  43: dfC[\"vwap\"] = lol[\"vwap\"]\n",
      "  44: dfC[\"bbmid\"] = lol[\"bbmid\"] / lol[\"close\"]\n",
      "  45: dfC[\"bbUpper\"] = lol[\"bbUpper\"] / lol[\"close\"]\n",
      "  46: dfC[\"bbLower\"] = lol[\"bbLower\"] / lol[\"close\"]\n",
      "  47: dfC[\"cci\"] = lol[\"cci\"] \n",
      "  48: dfC[\"rsi\"] = lol[\"rsi\"] \n",
      "  49: dfC[\"5max\"] = lol[\"5max\"] / lol[\"close\"]\n",
      "  50: dfC[\"10max\"] = lol[\"10max\"] / lol[\"close\"]\n",
      "  51: dfC[\"20max\"] = lol[\"20max\"] / lol[\"close\"]\n",
      "  52: dfC[\"5low\"] = lol[\"5low\"] / lol[\"close\"]\n",
      "  53: dfC[\"10low\"] = lol[\"10low\"] / lol[\"close\"]\n",
      "  54: dfC[\"20low\"] = lol[\"20low\"] / lol[\"close\"]\n",
      "  55: dfC[\"1pred\"] = lol[\"1pred\"]\n",
      "  56: dfC[\"3pred\"] = lol[\"3pred\"]\n",
      "  57: dfC[\"5pred\"] = lol[\"5pred\"]\n",
      "  58: dfC[\"10pred\"] = lol[\"10pred\"]\n",
      "  59: dfC[\"1predB\"] = lol[\"1predB\"]\n",
      "  60: dfC[\"3predB\"] = lol[\"3predB\"]\n",
      "  61: dfC[\"5predB\"] = lol[\"5predB\"]\n",
      "  62: dfC[\"10predB\"] = lol[\"10predB\"]\n",
      "  63: \n",
      "  64: dfC.replace([np.inf, -np.inf], np.nan)\n",
      "  65: dfC.dropna(inplace=True)\n",
      "  66: \n",
      "  67: X = dfC[['sma10', 'sma20', 'sma50', 'sma100', 'vwap', 'bbmid', 'bbUpper', 'bbLower', 'cci', 'rsi', '5max', '10max', '20max', '5low', '10low', '20low']]\n",
      "  68: Y = dfC[[\"5predB\"]]\n",
      "  69: \n",
      "  70: \n",
      "  71: x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
      "  72: \n",
      "  73: \n",
      "  74: \n",
      "  75: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \"\"\"\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     \"\"\"\n",
      "  13:     input_dim = x_train.shape[1]  # Number of features\n",
      "  14:     output_dim = y_train.shape[1]  # Number of features\n",
      "  15:     print(input_dim)\n",
      "  16:     model = Sequential()\n",
      "  17:     \n",
      "  18:     model.add(Dense(512, input_dim=input_dim))\n",
      "  19:     model.add(Activation(space['Activation']))\n",
      "  20:     model.add(Dense(space['Dense']))\n",
      "  21:     model.add(Activation(space['Activation_1']))\n",
      "  22:     model.add(Dense(space['Dense_1']))\n",
      "  23:     model.add(Activation(space['Activation_2']))\n",
      "  24: \n",
      "  25:     # If we choose 'four', add an additional fourth layer\n",
      "  26:     if space['Activation_3'] == 'four':\n",
      "  27:         # We can also choose between complete sets of layers\n",
      "  28: #         model.add(space['add'])\n",
      "  29:         model.add(Dense(space['Dense_2']))\n",
      "  30:         model.add(Activation(space['Activation_4']))\n",
      "  31: \n",
      "  32:     model.add(Dense(output_dim))\n",
      "  33:     model.add(Activation(space['Activation_5']))\n",
      "  34: \n",
      "  35:     model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
      "  36:                   optimizer=space['optimizer'])\n",
      "  37: \n",
      "  38:     es = EarlyStopping(monitor='val_loss', mode='min', patience=30)\n",
      "  39: \n",
      "  40:     result = model.fit(x_train, y_train,\n",
      "  41:             batch_size=space['batch_size'],\n",
      "  42:              epochs=100,\n",
      "  43:              validation_split=0.1,\n",
      "  44:              callbacks=[es])\n",
      "  45:     \n",
      "  46:     #get the highest validation accuracy of the training epochs\n",
      "  47:     validation_acc = np.amax(result.history['val_acc']) \n",
      "  48:     print('Best validation acc of epoch:', validation_acc)\n",
      "  49:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
      "  50: \n",
      "16                                                                                                                     \n",
      "Train on 1543 samples, validate on 172 samples                                                                         \n",
      "Epoch 1/100                                                                                                            \n",
      "  32/1543 [..............................]                                                                             \n",
      " - ETA: 37s - loss: 0.6931 - acc: 0.5312                                                                               \n",
      "                                                                                                                      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 384/1543 [======>.......................]                                                                             \n",
      " - ETA: 2s - loss: 0.6932 - acc: 0.4896                                                                                \n",
      "                                                                                                                       \n",
      " 736/1543 [=============>................]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5122                                                                                \n",
      "                                                                                                                       \n",
      "1056/1543 [===================>..........]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5142                                                                                \n",
      "                                                                                                                       \n",
      "1408/1543 [==========================>...]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5142                                                                                \n",
      "                                                                                                                       \n",
      "1543/1543 [==============================]                                                                             \n",
      " - 1s 708us/step - loss: 0.6931 - acc: 0.5139 - val_loss: 0.6937 - val_acc: 0.4419                                     \n",
      "\n",
      "Epoch 2/100                                                                                                            \n",
      "  32/1543 [..............................]                                                                             \n",
      " - ETA: 0s - loss: 0.6937 - acc: 0.4375                                                                                \n",
      "                                                                                                                       \n",
      " 384/1543 [======>.......................]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5026                                                                                \n",
      "                                                                                                                       \n",
      " 672/1543 [============>.................]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5015                                                                                \n",
      "                                                                                                                       \n",
      " 960/1543 [=================>............]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5115                                                                                \n",
      "                                                                                                                       \n",
      "1280/1543 [=======================>......]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5102                                                                                \n",
      "                                                                                                                       \n",
      "1536/1543 [============================>.]                                                                             \n",
      " - ETA: 0s - loss: 0.6930 - acc: 0.5150                                                                                \n",
      "                                                                                                                       \n",
      "1543/1543 [==============================]                                                                             \n",
      " - 0s 191us/step - loss: 0.6930 - acc: 0.5152 - val_loss: 0.6941 - val_acc: 0.4419                                     \n",
      "\n",
      "Epoch 3/100                                                                                                            \n",
      "  32/1543 [..............................]                                                                             \n",
      " - ETA: 0s - loss: 0.6952 - acc: 0.3750                                                                                \n",
      "                                                                                                                       \n",
      " 352/1543 [=====>........................]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5000                                                                                \n",
      "                                                                                                                       \n",
      " 704/1543 [============>.................]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5099                                                                                \n",
      "                                                                                                                       \n",
      "1024/1543 [==================>...........]                                                                             \n",
      " - ETA: 0s - loss: 0.6933 - acc: 0.4941                                                                                \n",
      "                                                                                                                       \n",
      "1216/1543 [======================>.......]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5082                                                                                \n",
      "                                                                                                                       \n",
      "1440/1543 [==========================>...]                                                                             \n",
      " - ETA: 0s - loss: 0.6929 - acc: 0.5194                                                                                \n",
      "                                                                                                                       \n",
      "1543/1543 [==============================]                                                                             \n",
      " - 0s 204us/step - loss: 0.6930 - acc: 0.5152 - val_loss: 0.6945 - val_acc: 0.4419                                     \n",
      "\n",
      "Epoch 4/100                                                                                                            \n",
      "  32/1543 [..............................]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5000                                                                                \n",
      "                                                                                                                       \n",
      " 384/1543 [======>.......................]                                                                             \n",
      " - ETA: 0s - loss: 0.6927 - acc: 0.5234                                                                                \n",
      "                                                                                                                       \n",
      " 704/1543 [============>.................]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5000                                                                                \n",
      "                                                                                                                       \n",
      " 992/1543 [==================>...........]                                                                             \n",
      " - ETA: 0s - loss: 0.6929 - acc: 0.5151                                                                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \n",
      "1216/1543 [======================>.......]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5058                                                                                \n",
      "                                                                                                                       \n",
      "1408/1543 [==========================>...]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5085                                                                                \n",
      "                                                                                                                       \n",
      "1543/1543 [==============================]                                                                             \n",
      " - 0s 197us/step - loss: 0.6929 - acc: 0.5152 - val_loss: 0.6949 - val_acc: 0.4419                                     \n",
      "\n",
      "Epoch 5/100                                                                                                            \n",
      "  32/1543 [..............................]                                                                             \n",
      " - ETA: 0s - loss: 0.6906 - acc: 0.5938                                                                                \n",
      "                                                                                                                       \n",
      " 416/1543 [=======>......................]                                                                             \n",
      " - ETA: 0s - loss: 0.6926 - acc: 0.5216                                                                                \n",
      "                                                                                                                       \n",
      " 736/1543 [=============>................]                                                                             \n",
      " - ETA: 0s - loss: 0.6931 - acc: 0.5054                                                                                \n",
      "                                                                                                                       \n",
      "1088/1543 [====================>.........]                                                                             \n",
      " - ETA: 0s - loss: 0.6932 - acc: 0.5046                                                                                \n",
      "                                                                                                                       \n",
      "1472/1543 [===========================>..]                                                                             \n",
      " - ETA: 0s - loss: 0.6928 - acc: 0.5170                                                                                \n",
      "                                                                                                                       \n",
      "1543/1543 [==============================]                                                                             \n",
      " - 0s 160us/step - loss: 0.6928 - acc: 0.5152 - val_loss: 0.6953 - val_acc: 0.4419                                     \n",
      "\n",
      "Epoch 6/100                                                                                                            \n",
      "  32/1543 [..............................]                                                                             \n",
      " - ETA: 0s - loss: 0.7009 - acc: 0.2812                                                                                \n",
      "                                                                                                                       \n",
      " 384/1543 [======>.......................]                                                                             \n",
      " - ETA: 0s - loss: 0.6953 - acc: 0.4349                                                                                \n",
      "  0%|                                                                              | 0/5 [00:02<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-016d4443e73a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    130\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m                                       \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kerasPrice'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                                       trials=Trials())\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[0;32m     67\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                                      \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m                                      keep_temp=keep_temp)\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[0;32m    137\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m              return_argmin=True),\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     )\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m             \u001b[0mshow_progressbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         )\n\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n\u001b[0;32m    637\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m             show_progressbar=show_progressbar)\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\jupyter\\kpi\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\3.7\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def data():\n",
    "    \"\"\"\n",
    "    Data providing function:\n",
    "\n",
    "    This function is separated from create_model() so that hyperopt\n",
    "    won't reload data for each evaluation run.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"./stockPrice.csv\", header=0, na_values='.')\n",
    "\n",
    "    lol = df.copy()\n",
    "    lol[\"1pred\"] = (df[\"close\"].shift(-1) - df[\"close\"]) / df[\"close\"]\n",
    "    lol[\"3pred\"] = (df[\"close\"].shift(-3) - df[\"close\"]) / df[\"close\"]\n",
    "    lol[\"5pred\"] = (df[\"close\"].shift(-5) - df[\"close\"]) / df[\"close\"]\n",
    "    lol[\"10pred\"] = (df[\"close\"].shift(-10) - df[\"close\"]) / df[\"close\"]\n",
    "\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '1predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '1predB'] = 1\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '3predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '3predB'] = 1\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '5predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '5predB'] = 1\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '10predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '10predB'] = 1\n",
    "\n",
    "    lol[\"5max\"] = lol[\"close\"].rolling(window=5).max()\n",
    "    lol[\"10max\"] = lol[\"close\"].rolling(window=10).max()\n",
    "    lol[\"20max\"] = lol[\"close\"].rolling(window=20).max()\n",
    "\n",
    "    lol[\"5low\"] = lol[\"close\"].rolling(window=5).min()\n",
    "    lol[\"10low\"] = lol[\"close\"].rolling(window=10).min()\n",
    "    lol[\"20low\"] = lol[\"close\"].rolling(window=20).min()\n",
    "\n",
    "    lol[\"vol%\"] =  (df[\"vol\"] - df[\"vol\"].shift(1)) /df[\"vol\"].shift(1)\n",
    "\n",
    "    lol = lol.dropna()    \n",
    "\n",
    "    dfC = pd.DataFrame()\n",
    "    dfC[\"vol\"] = lol[\"vol%\"]\n",
    "    dfC[\"sma10\"] = lol[\"sma10\"] / lol[\"close\"]\n",
    "    dfC[\"sma20\"] = lol[\"sma20\"] / lol[\"close\"]\n",
    "    dfC[\"sma50\"] = lol[\"sma50\"] / lol[\"close\"]\n",
    "    dfC[\"sma100\"] = lol[\"sma100\"] / lol[\"close\"]\n",
    "    dfC[\"vwap\"] = lol[\"vwap\"]\n",
    "    dfC[\"bbmid\"] = lol[\"bbmid\"] / lol[\"close\"]\n",
    "    dfC[\"bbUpper\"] = lol[\"bbUpper\"] / lol[\"close\"]\n",
    "    dfC[\"bbLower\"] = lol[\"bbLower\"] / lol[\"close\"]\n",
    "    dfC[\"cci\"] = lol[\"cci\"] \n",
    "    dfC[\"rsi\"] = lol[\"rsi\"] \n",
    "    dfC[\"5max\"] = lol[\"5max\"] / lol[\"close\"]\n",
    "    dfC[\"10max\"] = lol[\"10max\"] / lol[\"close\"]\n",
    "    dfC[\"20max\"] = lol[\"20max\"] / lol[\"close\"]\n",
    "    dfC[\"5low\"] = lol[\"5low\"] / lol[\"close\"]\n",
    "    dfC[\"10low\"] = lol[\"10low\"] / lol[\"close\"]\n",
    "    dfC[\"20low\"] = lol[\"20low\"] / lol[\"close\"]\n",
    "    dfC[\"1pred\"] = lol[\"1pred\"]\n",
    "    dfC[\"3pred\"] = lol[\"3pred\"]\n",
    "    dfC[\"5pred\"] = lol[\"5pred\"]\n",
    "    dfC[\"10pred\"] = lol[\"10pred\"]\n",
    "    dfC[\"1predB\"] = lol[\"1predB\"]\n",
    "    dfC[\"3predB\"] = lol[\"3predB\"]\n",
    "    dfC[\"5predB\"] = lol[\"5predB\"]\n",
    "    dfC[\"10predB\"] = lol[\"10predB\"]\n",
    "\n",
    "    dfC.replace([np.inf, -np.inf], np.nan)\n",
    "    dfC.dropna(inplace=True)\n",
    "\n",
    "    X = dfC[['sma10', 'sma20', 'sma50', 'sma100', 'vwap', 'bbmid', 'bbUpper', 'bbLower', 'cci', 'rsi', '5max', '10max', '20max', '5low', '10low', '20low']]\n",
    "    Y = dfC[[\"5predB\"]]\n",
    "\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    input_dim = x_train.shape[1]  # Number of features\n",
    "    output_dim = y_train.shape[1]  # Number of features\n",
    "    print(input_dim)\n",
    "\n",
    "        with tf.device('/gpu:1'):\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=input_dim))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "        model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "        model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "\n",
    "        # If we choose 'four', add an additional fourth layer\n",
    "        if {{choice(['three', 'four'])}} == 'four':\n",
    "            # We can also choose between complete sets of layers\n",
    "    #         model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "            model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "            model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "\n",
    "        model.add(Dense(output_dim))\n",
    "        model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "\n",
    "        model.compile(loss={{choice(['binary_crossentropy', 'categorical_crossentropy'])}}, metrics=['accuracy'],\n",
    "                      optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "        es = EarlyStopping(monitor='val_loss', mode='min', patience=20)\n",
    "\n",
    "        result = model.fit(x_train, y_train,\n",
    "                batch_size={{choice([16, 32])}},\n",
    "                 epochs=100,\n",
    "                 validation_split=0.1,\n",
    "                 callbacks=[es])\n",
    "\n",
    "        #get the highest validation accuracy of the training epochs\n",
    "        validation_acc = np.amax(result.history['val_acc']) \n",
    "        print('Best validation acc of epoch:', validation_acc)\n",
    "        return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "\n",
    "best_run, best_model = optim.minimize(model=create_model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      notebook_name='kerasPrice',\n",
    "                                      trials=Trials())\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evalutation of best performing model:\n",
      "735/735 [==============================] - ETA:  - 0s 65us/step\n",
      "[7.808515387814061, 0.510204081186632]\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Activation': 0, 'Activation_1': 0, 'Activation_2': 0, 'Activation_3': 1, 'Dense': 1, 'Dense_1': 1, 'Dense_2': 2, 'add': 0, 'batch_size': 1, 'optimizer': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, y_train, x_test, y_test = data()\n",
    "# input_dim = x_train.shape[1]  # Number of features\n",
    "# output_dim = y_train.shape[1]  # Number of features\n",
    "# print(input_dim)\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Dense(512, input_dim=input_dim))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(512))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(1024))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dense(output_dim))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy', metrics=['accuracy'],\n",
    "#               optimizer='adam')\n",
    "\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', patience=30)\n",
    "\n",
    "# model_output = model.fit(x_train, y_train,\n",
    "#                         batch_size=32,\n",
    "#                         epochs=100,\n",
    "#                         validation_split=0.1,\n",
    "#                         callbacks=[es])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, accuracy = model.evaluate(x_train, y_train, verbose=False)\n",
    "# print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "# loss, accuracy = model.evaluate(x_test, y_test, verbose=False)\n",
    "# print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "\n",
    "\n",
    "# print('Training Accuracy : ' , np.mean(model_output.history[\"acc\"]))\n",
    "# print('Validation Accuracy : ' , np.mean(model_output.history[\"val_acc\"]))\n",
    "\n",
    "\n",
    "\n",
    "# # Plot training & validation accuracy values\n",
    "# plt.plot(model_output.history['acc'])\n",
    "# plt.plot(model_output.history['val_acc'])\n",
    "# plt.title('Model accuracy')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# # Plot training & validation loss values\n",
    "# plt.plot(model_output.history['loss'])\n",
    "# plt.plot(model_output.history['val_loss'])\n",
    "# plt.title('model_output loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['Train', 'Test'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
