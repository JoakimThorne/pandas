{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/DarkKnight1991/Stock-Price-Prediction/blob/master/stock_pred_main.py\n",
    "# https://towardsdatascience.com/predicting-stock-price-with-lstm-13af86a74944\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd \n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "import pickle\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
    "from keras import optimizers\n",
    "# from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEPS = 10\n",
    "test_set_size_percentage = 20 \n",
    "COLUMNS = ['close', 'sma10', 'sma20', 'sma50', 'sma100', 'vwap', 'bbmid', 'bbUpper', 'bbLower', 'cci', 'rsi', '5max', '10max', '20max', '5low', '10low', '20low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create train, validation, test data given stock data and sequence length\n",
    "def load_data(stock, seq_len):\n",
    "    data_raw = stock.as_matrix() # convert to numpy array\n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - seq_len): \n",
    "        data.append(data_raw[index: index + seq_len])\n",
    "    \n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    \n",
    "    x_test = data[train_set_size:,:-1,:]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(df):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    for column in df:\n",
    "        df[column] = min_max_scaler.fit_transform(df[column].values.reshape(-1,1))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    TIME_STEPS = 10\n",
    "    test_set_size_percentage = 20 \n",
    "    COLUMNS = ['close', 'sma10', 'sma20', 'sma50', 'sma100', 'vwap', 'bbmid', 'bbUpper', 'bbLower', 'cci', 'rsi', '5max', '10max', '20max', '5low', '10low', '20low']\n",
    "\n",
    "    df = pd.read_csv(\"./stockPrice.csv\", header=0, na_values='.')\n",
    "\n",
    "    lol = df.copy()\n",
    "    lol[\"1pred\"] = (df[\"close\"].shift(-1) - df[\"close\"]) / df[\"close\"]\n",
    "    lol[\"3pred\"] = (df[\"close\"].shift(-3) - df[\"close\"]) / df[\"close\"]\n",
    "    lol[\"5pred\"] = (df[\"close\"].shift(-5) - df[\"close\"]) / df[\"close\"]\n",
    "    lol[\"10pred\"] = (df[\"close\"].shift(-10) - df[\"close\"]) / df[\"close\"]\n",
    "\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '1predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '1predB'] = 1\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '3predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '3predB'] = 1\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '5predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '5predB'] = 1\n",
    "    lol.loc[df[\"close\"].shift(-1) > df[\"close\"] , '10predB'] = 0\n",
    "    lol.loc[df[\"close\"].shift(-1) < df[\"close\"] , '10predB'] = 1\n",
    "\n",
    "    lol[\"5max\"] = lol[\"close\"].rolling(window=5).max()\n",
    "    lol[\"10max\"] = lol[\"close\"].rolling(window=10).max()\n",
    "    lol[\"20max\"] = lol[\"close\"].rolling(window=20).max()\n",
    "\n",
    "    lol[\"5low\"] = lol[\"close\"].rolling(window=5).min()\n",
    "    lol[\"10low\"] = lol[\"close\"].rolling(window=10).min()\n",
    "    lol[\"20low\"] = lol[\"close\"].rolling(window=20).min()\n",
    "\n",
    "    lol[\"vol%\"] =  (df[\"vol\"] - df[\"vol\"].shift(1)) /df[\"vol\"].shift(1)\n",
    "\n",
    "    lol = lol.dropna()    \n",
    "\n",
    "    dfC = pd.DataFrame()\n",
    "    dfC[\"vol\"] = lol[\"vol%\"]\n",
    "    dfC[\"sma10\"] = lol[\"sma10\"] / lol[\"close\"]\n",
    "    dfC[\"sma20\"] = lol[\"sma20\"] / lol[\"close\"]\n",
    "    dfC[\"sma50\"] = lol[\"sma50\"] / lol[\"close\"]\n",
    "    dfC[\"sma100\"] = lol[\"sma100\"] / lol[\"close\"]\n",
    "    dfC[\"vwap\"] = lol[\"vwap\"]\n",
    "    dfC[\"bbmid\"] = lol[\"bbmid\"] / lol[\"close\"]\n",
    "    dfC[\"bbUpper\"] = lol[\"bbUpper\"] / lol[\"close\"]\n",
    "    dfC[\"bbLower\"] = lol[\"bbLower\"] / lol[\"close\"]\n",
    "    dfC[\"cci\"] = lol[\"cci\"] \n",
    "    dfC[\"rsi\"] = lol[\"rsi\"] \n",
    "    dfC[\"5max\"] = lol[\"5max\"] / lol[\"close\"]\n",
    "    dfC[\"10max\"] = lol[\"10max\"] / lol[\"close\"]\n",
    "    dfC[\"20max\"] = lol[\"20max\"] / lol[\"close\"]\n",
    "    dfC[\"5low\"] = lol[\"5low\"] / lol[\"close\"]\n",
    "    dfC[\"10low\"] = lol[\"10low\"] / lol[\"close\"]\n",
    "    dfC[\"20low\"] = lol[\"20low\"] / lol[\"close\"]\n",
    "    dfC[\"1pred\"] = lol[\"1pred\"]\n",
    "    dfC[\"3pred\"] = lol[\"3pred\"]\n",
    "    dfC[\"5pred\"] = lol[\"5pred\"]\n",
    "    dfC[\"10pred\"] = lol[\"10pred\"]\n",
    "    dfC[\"1predB\"] = lol[\"1predB\"]\n",
    "    dfC[\"3predB\"] = lol[\"3predB\"]\n",
    "    dfC[\"5predB\"] = lol[\"5predB\"]\n",
    "    dfC[\"10predB\"] = lol[\"10predB\"]\n",
    "    dfC[\"close\"] = lol[\"close\"]\n",
    "\n",
    "    dfC.replace([np.inf, -np.inf], np.nan)\n",
    "    dfC.dropna(inplace=True)\n",
    "\n",
    "    df = dfC[COLUMNS]\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    for column in df:\n",
    "        df[column] = min_max_scaler.fit_transform(df[column].values.reshape(-1,1))\n",
    "\n",
    "    \n",
    "    data_raw = df.as_matrix() # convert to numpy array\n",
    "    data = []\n",
    "\n",
    "    # create all possible sequences of length seq_len\n",
    "    for index in range(len(data_raw) - TIME_STEPS): \n",
    "        data.append(data_raw[index: index + TIME_STEPS])\n",
    "\n",
    "    data = np.array(data);\n",
    "    test_set_size = int(np.round(test_set_size_percentage/100*data.shape[0]));\n",
    "    train_set_size = data.shape[0] - (test_set_size);\n",
    "\n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "\n",
    "\n",
    "    x_test = data[train_set_size:,:-1,:]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Choose only close prices\n",
    "    # x_train, y_train, x_test, y_test\n",
    "#     y_train = y_train[:,0]\n",
    "#     y_test = y_test[:,0]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-409-5f78b5b3e3d6>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-409-5f78b5b3e3d6>\"\u001b[1;36m, line \u001b[1;32m26\u001b[0m\n\u001b[1;33m    {{choice([256, 512, 1024])}},\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    \"\"\"\n",
    "    input_dim = x_train.shape[2]  # Number of features\n",
    "    output_dim = y_train.shape[2]  # Number of features\n",
    "    print(input_dim)\n",
    "    TIME_STEPS = 10\n",
    "\n",
    "#     ''''''''''''''''''''''''''''''''''''''''''''''\n",
    "    model = Sequential()\n",
    "\n",
    " # (batch_size, timesteps, data_dim)\n",
    "#     model.add(LSTM({{choice([256, 512, 1024])}}, batch_input_shape=(20, TIME_STEPS, input_dim),\n",
    "#                         dropout=0.0, recurrent_dropout=0.0, stateful=True, return_sequences=True,\n",
    "#                         kernel_initializer='random_uniform'))\n",
    "#     model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(LSTM(input_dim = input_dim,\n",
    "                   {{choice([256, 512, 1024])}},\n",
    "                        return_sequences=False))    \n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "\n",
    "    model.add(Dense(output_dim))\n",
    "    model.add(Activation({{choice(['sigmoid','softmax'])}}))\n",
    "    \n",
    "    \n",
    "    optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    # optimizer = optimizers.SGD(lr=0.000001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    \n",
    "#     optimizer = optimizers.RMSprop(lr=params[\"lr\"])\n",
    "    # optimizer = optimizers.SGD(lr=0.000001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#     model.compile(loss='mean_squared_error', optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,\n",
    "                       patience=40, min_delta=0.0001)\n",
    "                                                             \n",
    "    result = model.fit(x_train, y_train,\n",
    "             batch_size=1,\n",
    "             epochs=300,\n",
    "             callbacks=[es],\n",
    "             shuffle=False,\n",
    "             validation_split=0.1)\n",
    "                                                             \n",
    "    score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\joaki\\.conda\\envs\\3.7\\lib\\site-packages\\ipykernel_launcher.py:72: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1952, 17)\n",
      "Evalutation of best performing model:\n",
      "Best performing model chosen hyper-parameters:\n"
     ]
    }
   ],
   "source": [
    "# best_run, best_model = optim.minimize(model=create_model,\n",
    "#                                       data=getData,\n",
    "#                                       algo=tpe.suggest,\n",
    "#                                       max_evals=10,\n",
    "#                                       notebook_name='kpiLstmHyperas',\n",
    "#                                       trials=Trials())\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = getData()\n",
    "print(Y_train)\n",
    "print(Y_train.shape)\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "# print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "# print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model(x_train, y_train, x_test, y_test):\n",
    "#     \"\"\"\n",
    "#     Model providing function:\n",
    "\n",
    "#     Create Keras model with double curly brackets dropped-in as needed.\n",
    "#     Return value has to be a valid python dictionary with two customary keys:\n",
    "#         - loss: Specify a numeric evaluation metric to be minimized\n",
    "#         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "#     The last one is optional, though recommended, namely:\n",
    "#         - model: specify the model just created so that we can later use it again.\n",
    "#     \"\"\"\n",
    "#     input_dim = x_train.shape[1]  # Number of features\n",
    "#     output_dim = y_train.shape[1]  # Number of features\n",
    "#     print(input_dim)\n",
    "\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Dense(512, input_dim=input_dim))\n",
    "#     model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "#     model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "#     model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "#     model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "#     model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "\n",
    "#     # If we choose 'four', add an additional fourth layer\n",
    "#     if {{choice(['three', 'four'])}} == 'four':\n",
    "#         model.add(Dense(100))\n",
    "#         # We can also choose between complete sets of layers\n",
    "#         model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "#         model.add(Activation({{choice(['relu', 'sigmoid','softmax'])}}))\n",
    "        \n",
    "#     model.add(Dense(output_dim))\n",
    "#     model.add(Activation('sigmoid'))\n",
    "\n",
    "#     model.compile(loss='binary_crossentropy', metrics=['accuracy'],\n",
    "#                   optimizer={{choice(['rmsprop', 'adam', 'sgd'])}})\n",
    "\n",
    "#     result = model.fit(x_train, y_train,\n",
    "#              batch_size={{choice([16, 32, 64])}},\n",
    "#              epochs=100,\n",
    "#              validation_data=(x_test, y_test))\n",
    "\n",
    "#     score, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "#     print('Test accuracy:', acc)\n",
    "#     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "\n",
    "# best_run, best_model = optim.minimize(model=create_model,\n",
    "#                                       data=data,\n",
    "#                                       algo=tpe.suggest,\n",
    "#                                       max_evals=10,\n",
    "#                                       notebook_name='kpiLstmHyperas',\n",
    "#                                       trials=Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
